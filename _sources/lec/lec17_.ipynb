{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513f836",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 3.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd085495",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 17: Quasi-Newton methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0073d40a",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import feedback\n",
    "\n",
    "feedback.feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b32f6ec",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Week 11 room changes!\n",
    "\n",
    "| | | |\n",
    "|-|-|-|\n",
    "| Thu 14 Dec | 12:00-13:00 | Conference Auditorium 1 (GM.03) |\n",
    "| Fri 15 Dec | 11:00-12:00 | Roger Stevens LT 21 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4bde958",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The problem\n",
    "\n",
    "> Given a continuous function $f(x)$, the problem is to find a point $x^*$ such that $f(x^*) = 0$. That is, $x^*$ is a solution of the equation $f(x) = 0$ and is called a **root of $f(x)$**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8804238",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Recall Newton's method:\n",
    "\n",
    "$$x^{(i+1)} = x^{(i)} - \\frac{f(x^{(i)})}{f'(x^{(i)})}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8115fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton(f, df, x0, tol=1.0e-10):\n",
    "    x = x0\n",
    "\n",
    "    while abs(f(x)) > tol:\n",
    "        x = x - f(x) / df(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3114e5f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Newton's method requires **function** and **it's derivative**.\n",
    "\n",
    "This may not be possible since:\n",
    "\n",
    "- $f(x)$ may be a \"black box\"\n",
    "- the formula for $f(x)$ may be known but difficult to differentiate\n",
    "- the derivative maybe *very* expensive to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3579657d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Approximating f'(x)\n",
    "\n",
    "Let's approximate $f'(x)$ like we approximated $y'(t)$ when solving a differential equation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7d21df",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return np.exp(-(x**2))\n",
    "\n",
    "\n",
    "def plot(dt=1.0):\n",
    "    t = np.linspace(-2, 2, 200)\n",
    "    plt.plot(t, f(t))\n",
    "\n",
    "    plt.plot([0, 0, -2], [0, f(0), f(0)], \"--\")\n",
    "    plt.plot([dt, dt, -2], [0, f(dt), f(dt)], \"--\")\n",
    "\n",
    "    slope = (f(dt) - f(0)) / dt\n",
    "    plt.plot([0, dt], [f(0), f(dt)], label=f\"{slope=:.1f}\")\n",
    "\n",
    "    plt.xticks([0, dt], [\"t\", \"t + dt\"])\n",
    "    plt.yticks([f(0), f(dt)], [\"f(t)\", \"f(t + dt)\"])\n",
    "\n",
    "    plt.grid(\"off\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5a1e38",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Modified Newton's method\n",
    "\n",
    "-   Recall that $f'(x) = \\lim_{\\mathrm{d}x \\to 0} \\frac{f(x + \\mathrm{d}x) - f(x)}{\\mathrm{d}x}$.\n",
    "\n",
    "-   Hence we can choose a small value for $\\mathrm{d}x$ (how small?) and approximate:\n",
    "\n",
    "    $$\n",
    "    f'(x) \\approx \\frac{f(x + \\mathrm{d}x) - f(x)}{\\mathrm{d}x}.\n",
    "    $$\n",
    "\n",
    "-   This modified-Newton method then becomes\n",
    "\n",
    "    $$\n",
    "    x^{(i+1)} = x^{(i)} - \\frac{\\mathrm{d}x \\times f(x^{(i)})}{f(x^{(i)} + \\mathrm{d}x) - f(x^{(i)})}.\n",
    "    $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8ad707",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def modified_newton(f, x0, dx, tol=1.0e-10):\n",
    "    x = x0\n",
    "\n",
    "    while abs(f(x)) > tol:\n",
    "        df = (f(x + dx) - f(x)) / dx  # two extra evaluations of f\n",
    "        # per iteration\n",
    "        x = x - f(x) / df\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c06c02",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def modified_newton2(f, x0, dx, tol=1.0e-10):\n",
    "    x = x0\n",
    "    fx = f(x)\n",
    "\n",
    "    while abs(fx) > tol:\n",
    "        df = (f(x + dx) - fx) / dx  # one extra evaluations of f\n",
    "        # per iteration\n",
    "        x = x - fx / df\n",
    "        fx = f(x)  # one original evaluation of f per iteration\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7bcf45",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Graphical representation of modified Newton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d87e58",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1)\n",
    "f = lambda x: np.tanh(x / 0.5 - 0.1)\n",
    "df = lambda x: 2 * np.cosh(2.0 * x - 0.1) ** -2\n",
    "fx = f(x)\n",
    "\n",
    "plt.axhline(0, color=\"0\")  # x = 0\n",
    "\n",
    "x0 = 0.4\n",
    "dx = 0.25\n",
    "\n",
    "x1 = x0 - dx * f(x0) / (f(x0 + dx) - f(x0))\n",
    "\n",
    "plt.plot([x0, x0, -1], [-1, f(x0), f(x0)], \"0.80\")\n",
    "plt.plot([x0 + dx, x0 + dx, -1], [-1, f(x0 + dx), f(x0 + dx)], \"0.80\")\n",
    "plt.plot([x1, x1], [-1, 0.0], \"0.80\")\n",
    "\n",
    "plt.xticks([x0, x0 + dx, x1], [\"$x^{(0)}$\", \"$x^{(0)} + \\mathrm{d}x$\", \"$x^{(1)}$\"])\n",
    "plt.yticks([f(x0), f(x0 + dx)], [\"$f(x^{(0)})$\", \"$f(x^{(0)} + \\mathrm{d}x)$\"])\n",
    "\n",
    "plt.plot(x, fx)\n",
    "l = plt.plot([x0, x0 + dx], [f(x0), f(x0) + dx], \"o\")\n",
    "plt.plot(x1, f(x1), \"o\")\n",
    "\n",
    "plt.plot(x, f(x0) + (x - x0) * (f(x0 + dx) - f(x0)) / dx, color=l[0].get_color())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d9ac16",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How to choose $\\mathrm{d}x$?\n",
    "\n",
    "**Smaller** - more accurate approximation\n",
    "\n",
    "**Large** - too small and we will have rounding problems (subtracting two similar numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34dbfd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "-   When $f(x) = x^3$ then $f'(x) = 3 x^2$.\n",
    "\n",
    "-   Hence, at $x_0 = 1$, $f(x_0) = 1$ and $f'(x_0) = 3$.\n",
    "\n",
    "-   Consider what happens when we approximate this with python, using finite values for $\\mathrm{d}x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dde7a4",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def cubic(x):\n",
    "    return x**3\n",
    "\n",
    "\n",
    "def d_cubic(x):\n",
    "    return 3 * x**2\n",
    "\n",
    "\n",
    "x = 1\n",
    "\n",
    "headers = [\"dx\", \"approx\", \"abs error\", \"rel error\"]\n",
    "data = []\n",
    "\n",
    "for e in range(4, 18, 2):\n",
    "    dx = 10**-e\n",
    "    approx = (cubic(x + dx) - cubic(x)) / dx\n",
    "    exact = d_cubic(x)\n",
    "    abs_error = abs(exact - approx)\n",
    "    rel_error = abs(exact - approx) / exact\n",
    "\n",
    "    new_data = [dx, approx, abs_error, rel_error]\n",
    "    data.append(new_data)\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df.style.format(\n",
    "    formatter={\"dx\": \"{:e}\", \"approx\": \"{:f}\", \"abs error\": \"{:e}\", \"rel error\": \"{:e}\"}\n",
    ").hide_index().set_caption(\n",
    "    \"Simple approximation of a derivative using floating point arithmetic\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484d2c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0.5, 1.5)\n",
    "exact = d_cubic(xx)\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 6))\n",
    "fig.suptitle(\"Approximations of the derivative\")\n",
    "\n",
    "ax1 = plt.subplot(121)\n",
    "ax2 = plt.subplot(122)\n",
    "\n",
    "for e in range(4, 18, 2):\n",
    "    dx = 10**-e\n",
    "    approx = (cubic(xx + dx) - cubic(xx)) / dx\n",
    "\n",
    "    ax1.plot(xx, approx, label=\"dx=$10^{\" + str(-e) + \"}$\")\n",
    "    ax2.semilogy(xx, abs(approx - exact))\n",
    "\n",
    "ax1.plot(xx, exact, \"k--\", label=\"exact\")\n",
    "\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"df\")\n",
    "ax1.grid()\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"abs error\")\n",
    "ax2.grid(\"on\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bfa02a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A special choice!\n",
    "\n",
    "- Recall the definition of machine precision/unit roundoff from Lecture 3.\n",
    "- The modified Newton method uses $\\mathrm{d}x = \\sqrt{eps}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce2820",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "eps = np.finfo(np.double).eps\n",
    "dx = np.sqrt(eps)\n",
    "\n",
    "print(f\"{eps=} {dx=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fb12a3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "xx = np.linspace(0.5, 1.5)\n",
    "exact = d_cubic(xx)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 6))\n",
    "fig.suptitle(\"A special approximation of the derivative\")\n",
    "\n",
    "for e in range(4, 18, 2):\n",
    "    dx = 10**-e\n",
    "    approx = (cubic(xx + dx) - cubic(xx)) / dx\n",
    "\n",
    "    ax1.plot(xx, approx, \"0.5\")\n",
    "    ax2.semilogy(xx, abs(approx - exact), \"0.5\")\n",
    "\n",
    "ax1.plot(xx, exact, \"k--\")\n",
    "\n",
    "eps = np.finfo(np.double).eps\n",
    "dx = np.sqrt(eps)\n",
    "\n",
    "approx = (cubic(xx + dx) - cubic(xx)) / dx\n",
    "\n",
    "ax1.plot(xx, approx, \"r\", label=r\"dx = $\\sqrt{eps}$\")\n",
    "ax2.semilogy(xx, abs(approx - exact), \"r\", label=r\"dx = $\\sqrt{eps}$\")\n",
    "\n",
    "ax1.set_xlabel(\"x\")\n",
    "ax1.set_ylabel(\"df\")\n",
    "ax1.grid(\"on\")\n",
    "ax1.legend()\n",
    "\n",
    "ax2.set_xlabel(\"x\")\n",
    "ax2.set_ylabel(\"abs error\")\n",
    "ax2.grid(\"on\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb55e56a",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def modified_newton_with_table(f, x0, tol=1.0e-10, maxiter=100):\n",
    "    eps = np.finfo(np.double).eps\n",
    "    dx = np.sqrt(eps)\n",
    "\n",
    "    x = np.double(x0)\n",
    "    it = 0\n",
    "\n",
    "    headers = [\"iter\", \"x\", \"f(x)\"]\n",
    "    data = []\n",
    "    data.append([it, x, f(x)])\n",
    "\n",
    "    while abs(f(x)) > tol:\n",
    "        it += 1\n",
    "\n",
    "        df = (f(x + dx) - f(x)) / dx\n",
    "        x = x - f(x) / df\n",
    "        data.append([it, x, f(x)])\n",
    "\n",
    "        if it > maxiter:\n",
    "            sys.stderr.write(\n",
    "                \"WARNING! Modified Newton iteration has not converged. \"\n",
    "                + \"Too many iterations.\\n\"\n",
    "            )\n",
    "            break\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90b1aa6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Example\n",
    "\n",
    "Recall the NACA0012 aerofoil example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1b24e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_naca0012(x):\n",
    "    t = 0.1\n",
    "\n",
    "    yp = (\n",
    "        -0.1015 * x**4\n",
    "        + 0.2843 * x**3\n",
    "        - 0.3516 * x**2\n",
    "        - 0.126 * x\n",
    "        + 0.2969 * np.sqrt(x)\n",
    "    )\n",
    "    f = yp - 0.5 * t\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a6f895",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def wing_shape(x):\n",
    "    yp = (\n",
    "        -0.1015 * np.power(x, 4)\n",
    "        + 0.2843 * np.power(x, 3)\n",
    "        - 0.3516 * np.power(x, 2)\n",
    "        - 0.126 * x\n",
    "        + 0.2969 * np.sqrt(x)\n",
    "    )\n",
    "    f = yp\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "t = np.linspace(0, 1, 1000)\n",
    "p = plt.plot(t, wing_shape(t))\n",
    "plt.plot(t, -wing_shape(t), color=p[0].get_color())\n",
    "plt.axis(\"equal\")\n",
    "plt.grid(\"on\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9455a3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Starting from $x^{(0)} = 1$ with $TOL = 10^{-4}$, we get the root as $x^* \\approx 0.765789$ after 2 iterations for the NACA0012 aerofoil example (Same as Newton!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe8ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_newton_with_table(f_naca0012, x0=1.0, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc0da3e5",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Starting from $x^{(0)} = 0.1$ with $TOL = 10^{-4}$, we get the root as $x^* \\approx 0.033863$ after 5 iterations for the second solution to the NACA0012 aerofoil example (Same as Newton!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c61f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_newton_with_table(f_naca0012, x0=0.1, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e108dbf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The secant method\n",
    "\n",
    "> Can we use a similar derivative approximation but avoid the extra function evaluation?\n",
    "\n",
    "Recall modified-Newton method:\n",
    "\n",
    "$$\n",
    "x^{(i+1)} = x^{(i)} - \\frac{\\mathrm{d}x \\times f(x^{(i)})}{f(x^{(i)} + \\mathrm{d}x) - f(x^{(i)})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b0881f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now with $\\mathrm{d}x = x^{(i)} - x^{(i-1)}$ becomes\n",
    "\n",
    "$$\n",
    "x^{(i+1)} = x^{(i)} - \\frac{(x^{(i)} - x^{(i-1)}) \\times f(x^{(i)})}{f(x^{(i)}) - f(x^{(i-1)})}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2208a7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def secant(f, x0, x1, tol=1.0e-10):\n",
    "    # two initial function evaluations\n",
    "    f0 = f(x0)\n",
    "    f1 = f(x1)\n",
    "\n",
    "    while abs(f1) > tol:\n",
    "        # compute derivative approximation\n",
    "        df = (f1 - f0) / (x1 - x0)\n",
    "        # update x\n",
    "        x2 = x1 - f1 / df\n",
    "\n",
    "        # update other variables\n",
    "        x0, f0 = x1, f1\n",
    "        x1, f1 = x2, f(x2)  # one evaluation of f per iteration\n",
    "\n",
    "    return x1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4648ab7d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## A geometric interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75ffaa0",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-1, 1)\n",
    "f = lambda x: np.tanh(x / 0.5 - 0.1)\n",
    "df = lambda x: 2 * np.cosh(2.0 * x - 0.1) ** -2\n",
    "fx = f(x)\n",
    "\n",
    "plt.axhline(0, color=\"0\")  # x = 0\n",
    "\n",
    "x0 = 0.4\n",
    "x1 = 0.6\n",
    "x2 = x1 - f(x1) * (x1 - x0) / (f(x1) - f(x0))\n",
    "\n",
    "plt.plot([x0, x0, -1], [-1, f(x0), f(x0)], \"0.80\")\n",
    "plt.plot([x1, x1, -1], [-1, f(x1), f(x1)], \"0.80\")\n",
    "plt.plot([x2, x2], [-1, 0.0], \"0.80\")\n",
    "\n",
    "plt.xticks([x0, x1, x2], [\"$x^{(0)}$\", \"$x^{(1)}$\", \"$x^{(2)}$\"])\n",
    "plt.yticks([f(x0), f(x1)], [\"$f(x^{(0)})$\", \"$f(x^{(1)})$\"])\n",
    "\n",
    "plt.plot(x, fx)\n",
    "l = plt.plot([x0, x1], [f(x0), f(x1)], \"o\")\n",
    "plt.plot(x2, f(x2), \"o\")\n",
    "\n",
    "plt.plot(x, f(x0) + (x - x0) * (f(x1) - f(x0)) / (x1 - x0), color=l[0].get_color())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37174c1",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def secant_with_table(f, x0, x1, tol=1.0e-10):\n",
    "    f0 = f(x0)\n",
    "    f1 = f(x1)\n",
    "\n",
    "    it = 0\n",
    "\n",
    "    headers = [\"iter\", \"x0\", \"f(x0)\", \"x1\", \"f(x1)\"]\n",
    "    data = []\n",
    "    data.append([it, x0, f0, x1, f1])\n",
    "\n",
    "    while abs(f1) > tol:\n",
    "        it = it + 1\n",
    "\n",
    "        df = (f1 - f0) / (x1 - x0)\n",
    "        x = x1 - f1 / df\n",
    "\n",
    "        x0, f0 = x1, f1\n",
    "        x1, f1 = x, f(x)  # one evaluation of f per iteration\n",
    "\n",
    "        data.append([it, x0, f0, x1, f1])\n",
    "\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    return df.style.hide_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2047c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Numerical examples\n",
    "\n",
    "- The naca0012 example starting from 1 and 0.9 to a tolerance of $10^{-4}$ gives the solution as $x^* \\approx 0.765264$ after 3 iterations (one more than Newton!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c82397",
   "metadata": {},
   "outputs": [],
   "source": [
    "secant_with_table(f_naca0012, x0=1.0, x1=0.9, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55603013",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Starting from $x^{(0)} = 0.0$ and $x^{(1)} = 0.1$ with $TOL = 10^{-4}$, we get the root as $x^* \\approx 0.033870$ after 5 iterations for the second solution to the NACA0012 aerofoil example (Same as Newton!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae2aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "secant_with_table(f_naca0012, x0=0.0, x1=0.1, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd017fe8",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Turning points?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39efcbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_turning(x):\n",
    "    return (x - 1) ** 2\n",
    "\n",
    "\n",
    "secant_with_table(f_turning, x0=4.0, x1=3.0, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe63f74",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Other problems\n",
    "\n",
    "Even more care is required to avoid divide by zero errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba852b7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# equal function values at x0 and x1\n",
    "secant(f_turning, x0=4.0, x1=-2.0, tol=1.0e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461e8a62",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [],
   "source": [
    "# too small tolerance means x0 = x1!\n",
    "secant(f_turning, x0=4.0, x1=3.0, tol=1.0e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "310d90c3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Exercise (hard!)\n",
    "\n",
    "Find a periodic iteration for the secant method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e4012",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary\n",
    "\n",
    "|                    | Bisection         | Newton's method            | Modified Newton   | Secant            |\n",
    "|--------------------|-------------------|----------------------------|-------------------|-------------------|\n",
    "| Simple algorithm   | yes               | yes                        | yes               | yes               |\n",
    "| Starting values    | bracket           | one                        | one               | two               |\n",
    "| Iterations         | lots              | normally fewer             | similar to Newton | similar to Newton |\n",
    "| Function evals     | one per iteration | `f` and `df` per iteration | two per iteration | one per iteration |\n",
    "| Convergence        | with good bracket | not always                 | not always        | not always        |\n",
    "| Turing point roots | no                | slower                     | slower            | slower            |\n",
    "| Use of derivative  | no                | yes                        | no                | no                |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56fbb77",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    t = 0.1\n",
    "\n",
    "    yp = (\n",
    "        -0.1015 * np.power(x, 4)\n",
    "        + 0.2843 * np.power(x, 3)\n",
    "        - 0.3516 * np.power(x, 2)\n",
    "        - 0.126 * x\n",
    "        + 0.2969 * np.sqrt(x)\n",
    "    )\n",
    "    f = yp - 0.5 * t\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def df(x):\n",
    "    dy = (\n",
    "        -4 * 0.1015 * np.power(x, 3)\n",
    "        + 3 * 0.2843 * np.power(x, 2)\n",
    "        - 2 * 0.3516 * x\n",
    "        - 0.126\n",
    "        + 0.2969 * 0.5 * np.power(x, -0.5)\n",
    "    )\n",
    "    f = dy\n",
    "\n",
    "    return f\n",
    "\n",
    "\n",
    "def bisection(func, a, b, tol=1.0e-10):\n",
    "    # Starting values\n",
    "    fa = func(a)\n",
    "    func(b)\n",
    "\n",
    "    feval = [2]\n",
    "    rets = [(a + b) / 2]\n",
    "\n",
    "    while b - a > tol:\n",
    "        # Find new mid point\n",
    "        c = (a + b) / 2\n",
    "        fc = func(c)\n",
    "\n",
    "        # if root is in left half of interval\n",
    "        if fa * fc < 0.0:\n",
    "            # move right end\n",
    "            b = c\n",
    "        else:\n",
    "            # otherwise,\n",
    "            # move the left end\n",
    "            a = c\n",
    "            fa = fc\n",
    "\n",
    "        feval.append(feval[-1] + 1)\n",
    "        rets.append((a + b) / 2)\n",
    "\n",
    "    return rets, feval\n",
    "\n",
    "\n",
    "def newton_values(f, df, x0, tol=1.0e-10):\n",
    "    x = x0\n",
    "\n",
    "    feval = [1]\n",
    "    rets = [x]\n",
    "\n",
    "    while abs(f(x)) > tol:\n",
    "        x = x - f(x) / df(x)\n",
    "        rets.append(x)\n",
    "        feval.append(feval[-1] + 2)\n",
    "\n",
    "    return rets, feval\n",
    "\n",
    "\n",
    "def modified_newton_values(f, x0, tol=1.0e-10, maxiter=100):\n",
    "    eps = np.finfo(np.double).eps\n",
    "    dx = np.sqrt(eps)\n",
    "\n",
    "    x = x0\n",
    "    rets = [x]\n",
    "    feval = [1]\n",
    "\n",
    "    while abs(f(x)) > tol:\n",
    "        df = (f(x + dx) - f(x)) / dx\n",
    "        x = x - f(x) / df\n",
    "\n",
    "        rets.append(x)\n",
    "        feval.append(feval[-1] + 2)\n",
    "\n",
    "    return rets, feval\n",
    "\n",
    "\n",
    "def secant(f, x0, x1, tol=1.0e-10):\n",
    "    # two initial function evaluations\n",
    "    f0 = f(x0)\n",
    "    f1 = f(x1)\n",
    "\n",
    "    feval = [2]\n",
    "    rets = [x1]\n",
    "\n",
    "    while abs(f1) > tol:\n",
    "        # compute derivative approximation\n",
    "        df = (f1 - f0) / (x1 - x0)\n",
    "        # update x\n",
    "        x2 = x1 - f1 / df\n",
    "\n",
    "        # update other variables\n",
    "        x0, f0 = x1, f1\n",
    "        x1, f1 = x2, f(x2)  # one evaluation of f per iteration\n",
    "\n",
    "        rets.append(x1)\n",
    "        feval.append(feval[-1] + 1)\n",
    "\n",
    "    return rets, feval\n",
    "\n",
    "\n",
    "tol = 1.0e-15\n",
    "bisection_rets, bisection_fevals = bisection(f, 0.5, 1.0, tol=tol)\n",
    "newton_rets, newton_fevals = newton_values(f, df, x0=1.0, tol=tol)\n",
    "modified_rets, modified_fevals = modified_newton_values(f, x0=1.0, tol=tol)\n",
    "secant_rets, secant_fevals = secant(f, x0=1.0, x1=0.5, tol=tol)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.semilogy([abs(f(x)) for x in bisection_rets], \".-\", label=\"bisection\")\n",
    "plt.semilogy([abs(f(x)) for x in newton_rets], \".-\", label=\"Newton\")\n",
    "plt.semilogy([abs(f(x)) for x in modified_rets], \".-\", label=\"Mod-Newton\")\n",
    "plt.semilogy([abs(f(x)) for x in secant_rets], \".-\", label=\"secant\")\n",
    "\n",
    "plt.title(\"Rates of convergence for iterations\")\n",
    "plt.xlabel(\"iter ($i$)\")\n",
    "plt.ylabel(\"$|f(x^{(i)})|$\")\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ea69b1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.semilogy(\n",
    "    bisection_fevals, [abs(f(x)) for x in bisection_rets], \".-\", label=\"bisection\"\n",
    ")\n",
    "plt.semilogy(newton_fevals, [abs(f(x)) for x in newton_rets], \".-\", label=\"Newton\")\n",
    "plt.semilogy(\n",
    "    modified_fevals, [abs(f(x)) for x in modified_rets], \".-\", label=\"Mod-Newton\"\n",
    ")\n",
    "plt.semilogy(secant_fevals, [abs(f(x)) for x in secant_rets], \".-\", label=\"secant\")\n",
    "\n",
    "plt.title(\"Rates of convergence for computational cost\")\n",
    "plt.xlabel(\"function (or derivative) evaluations\")\n",
    "plt.ylabel(\"$|f(x^{(i)})|$\")\n",
    "plt.legend()\n",
    "plt.grid(\"on\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

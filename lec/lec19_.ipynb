{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abf1301",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 3.1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c60248",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 19: Least squares fitting\n",
    "\n",
    "... time to starting thinking about ~~Christmas~~ ~~data~~ coursework! :(\n",
    "\n",
    "*Module feedback*: https://leeds.bluera.com/leeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3229ef99",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "import feedback\n",
    "\n",
    "feedback.feedback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c62a5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Motivation\n",
    "\n",
    "-   Suppose we are given data point representing a quantity over time.\n",
    "\n",
    "-   We want to represent the graph of this data as a simple curve.\n",
    "\n",
    "-   The examples on the following slide show the fitting of two different curves through some experimental data:\n",
    "\n",
    "    -   a straight line;\n",
    "    -   a quadratic curve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab54c994",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Weekly earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40fa8e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "data_url = \"http://www.ons.gov.uk/file?uri=/employmentandlabourmarket/peopleinwork/earningsandworkinghours/datasets/averageweeklyearningsearn01/current/earn01nov2024.xls\"\n",
    "r = requests.get(data_url)\n",
    "df = pd.read_excel(BytesIO(r.content), sheet_name=\"1. AWE Total Pay\")\n",
    "df = df.iloc[:, [0, 1]]\n",
    "df.columns = [\"date\", \"earnings\"]\n",
    "df = df.dropna()\n",
    "# since 2008\n",
    "df = df[df[\"date\"] > dt(2008, 1, 1)]\n",
    "\n",
    "\n",
    "def to_days(date):\n",
    "    return float((date - dt(2008, 1, 1)).days)\n",
    "\n",
    "\n",
    "days = df.apply(lambda row: to_days(row.date), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65c6201",
   "metadata": {},
   "source": [
    "Raw data for average UK weekly earnings since 2008 (from ONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c64a0f",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.plot(df[\"date\"], df[\"earnings\"], \".\", label=\"data\")\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"mean weekly earnings (£)\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab83c5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Raw data for weekly earning with a straight line of best fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28de7866",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def fit_line(x, y):\n",
    "    a = np.array([[d, 1] for d in x])\n",
    "    b = np.array([[e] for e in y])\n",
    "\n",
    "    ata = a.T @ a\n",
    "    atb = a.T @ b\n",
    "\n",
    "    coef = np.linalg.solve(ata, atb)\n",
    "    return lambda t: coef[0] * t + coef[1], coef\n",
    "\n",
    "\n",
    "fit1, coef = fit_line(days, df[\"earnings\"])\n",
    "\n",
    "plt.plot(df[\"date\"], df[\"earnings\"], \".\", label=\"data\")\n",
    "plt.plot(df[\"date\"], fit1(days), label=\"linear fit\")\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"mean weekly earnings (£)\")\n",
    "plt.title(f\"y = {coef[0][0]:.3f} t + {coef[1][0]:.3f}\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a59649",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Raw data for weekly earnings with a quadric curve of best fit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e8b731",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "def fit_quad(x, y):\n",
    "    A = np.array([[d * d, d, 1] for d in x])\n",
    "    b = np.array([[e] for e in y])\n",
    "\n",
    "    AtA = A.T @ A\n",
    "    Atb = A.T @ b\n",
    "\n",
    "    coef = np.linalg.solve(AtA, Atb)\n",
    "    return lambda t: coef[0] * t * t + coef[1] * t + coef[2], coef\n",
    "\n",
    "\n",
    "fit2, coef2 = fit_quad(days, df[\"earnings\"])\n",
    "\n",
    "plt.plot(df[\"date\"], df[\"earnings\"], \".\", label=\"data\")\n",
    "plt.plot(df[\"date\"], fit1(days), label=\"linear fit\")\n",
    "plt.plot(df[\"date\"], fit2(days), label=\"quadratic fit\")\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"mean weekly earnings (£)\")\n",
    "plt.title(f\"y = {coef2[0][0]:.3e} $t^2$ + {coef2[1][0]:.3e} t + {coef2[2][0]:.3f}\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d5bb1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    ".... how do we do this...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4404ee",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## An example of best linear fit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01657f0d",
   "metadata": {},
   "source": [
    "Suppose that the following measured data, $y$, is observed at different times $t$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|cccc}\n",
    "t & 1 & 2 & 3 & 4 \\\\\n",
    "\\hline\n",
    "y & 1 & 1.5 & 2.5 & 3.5\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35c85b3",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "tt = [1.0, 2.0, 3.0, 4.0]\n",
    "yy = [1.0, 1.5, 2.5, 3.5]\n",
    "\n",
    "plt.figure\n",
    "plt.plot(tt, yy, \"o\")\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8388a706",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{c|cccc}\n",
    "t & 1 & 2 & 3 & 4 \\\\\n",
    "\\hline\n",
    "y & 1 & 1.5 & 2.5 & 3.5\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "- Suppose we want to represent the data using a straight line: $y = m t + c$\n",
    "\n",
    "- An *exact fit* would require the following equations to be satisfied:\n",
    "\n",
    "$$\n",
    "    \\begin{aligned}\n",
    "    m \\times 1 + c & = 1 \\\\\n",
    "    m \\times 2 + c & = 1.5 \\\\\n",
    "    m \\times 3 + c & = 2.5 \\\\\n",
    "    m \\times 4 + c & = 3.5.\n",
    "    \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad757b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> This is a system of linear equations for $(m , c)$ but there are too many equations!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d306034",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## An example of best quadratic fit\n",
    "\n",
    "Suppose that the following measured data, $y$, is observed at different times $t$:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccccc}\n",
    "t & -1.0 & -0.5 & 0  & 0.5 & 1.0 \\\\\n",
    "\\hline\n",
    "y & 1.0 & 0.5 & 0.0 & 0.5 & 2.0\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d471230e",
   "metadata": {
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "tt = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "yy = [1.0, 0.5, 0.0, 0.5, 2.0]\n",
    "\n",
    "plt.plot(tt, yy, \"o\")\n",
    "\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad5f7b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$$\n",
    "\\begin{array}{c|ccccc}\n",
    "t & -1.0 & -0.5 & 0  & 0.5 & 1.0 \\\\\n",
    "\\hline\n",
    "y & 1.0 & 0.5 & 0.0 & 0.5 & 2.0\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "-   Consider representing this data as a quadratic line:\n",
    "\n",
    "    $$\n",
    "    y = a + b t + c t^2\n",
    "    $$\n",
    "\n",
    "-   An *exact fit* would require the following equations to be satisfied:\n",
    "\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    a + b \\times -1 + c \\times (-1)^2 & = 1 \\\\\n",
    "    a + b \\times -0.5 + c \\times (-0.5)^2 & = 0.5 \\\\\n",
    "    a + b \\times 0 + c \\times 0^2 & = 0 \\\\\n",
    "    a + b \\times 0.5 + c \\times 0.5^2 & = 0.5 \\\\\n",
    "    a + b \\times 1 + c \\times 1^2 & = 2.\n",
    "    \\end{aligned}\n",
    "    $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45b612e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> We recognise this as a system of linear equations for $(a, b, c)$ - but there are too many equations!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cffd6ff1",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Best approximation\n",
    "\n",
    "> Given that there is no *exact fit* solution to these **overdetermined systems** of equations what should we do?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee40b58",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What can we do?\n",
    "\n",
    "Recall the definition of the **residual** for the system $A \\vec{x} = \\vec{b}$:\n",
    "\n",
    "$$\n",
    "\\vec{r} = \\vec{b} - A \\vec{x},\n",
    "$$\n",
    "\n",
    "-   When $\\vec{r} = \\vec{0}$, then $\\vec{x} = \\vec{x}^*$ the exact solution.\n",
    "-   When there is no exact solution the next best thing is to make $\\vec{r}$ as small as possible.\n",
    "-   This means finding $\\vec{x}$ that **minimises** $\\| \\vec{r} \\|^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226912d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The normal equations\n",
    "\n",
    "*It turns out* that the $\\vec{x}$ that minimises $\\|\\vec{b} - A \\vec{x}\\|^2$ is the same $\\vec{x}$ that satisfies the following *square* system of equations:\n",
    "\n",
    "$$\n",
    "A^T A \\vec{x} = A^T \\vec{b}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b7aefd",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## The normal equations\n",
    "\n",
    "-   These equations are referred to as the **normal equations** for the overdetermined system $A \\vec{x} = \\vec{b}$.\n",
    "\n",
    "-   The square matrix $A^T A$ is generally non-singular (i.e., the solution is unique).\n",
    "\n",
    "-   You can find this solution using Gaussian elimination (for example).\n",
    "\n",
    "-   The normal equations, when solved, give the **best solution** to the original problem in the sense of minimising the Euclidean norm of the residual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a826d1d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 1\n",
    "\n",
    "Find the least squares approximation to the match the data:\n",
    "\n",
    "$$\n",
    "\\begin{array}{c|ccccc}\n",
    "t & -1.0 & -0.5 & 0  & 0.5 & 1.0 \\\\\n",
    "\\hline\n",
    "y & 1.0 & 0.5 & 0.0 & 0.5 & 2.0\n",
    "\\end{array}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef5c147",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": [
     "remove-input"
    ]
   },
   "outputs": [],
   "source": [
    "tt = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "yy = [1.0, 0.5, 0.0, 0.5, 2.0]\n",
    "\n",
    "\n",
    "plt.plot(tt, yy, \"o\", label=\"data\")\n",
    "\n",
    "fit, coef2 = fit_quad(tt, yy)\n",
    "tt = np.linspace(min(tt), max(tt))\n",
    "fitt = fit(tt)\n",
    "\n",
    "plt.plot(tt, fitt, label=\"fit\")\n",
    "plt.title(f\"y = {coef2[0][0]:.3f} $t^2$ + {coef2[1][0]:.3f} t + {coef2[2][0]:.3f}\")\n",
    "plt.xlabel(\"t\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb08aaf",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 2 (for you!)\n",
    "\n",
    "Find the least square approximation to the system given by\n",
    "\n",
    "$$\n",
    "    \\begin{pmatrix}\n",
    "    -2 & 2 & -1 \\\\\n",
    "    0 & 1 & 0 \\\\\n",
    "    3 & 1 & -2 \\\\\n",
    "    1 & 1 & 4\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "    x_1 \\\\ x_2 \\\\ x_3\n",
    "    \\end{pmatrix}\n",
    "     =\n",
    "     \\begin{pmatrix}\n",
    "     2 \\\\ 1 \\\\ 0 \\\\ -3\n",
    "     \\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34443172",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "A = np.array([[-2.0, 2.0, -1.0], [0.0, 1.0, 0.0], [3.0, 1.0, -2.0], [1.0, 1.0, 4.0]])\n",
    "b = np.array([[2.0], [1.0], [0.0], [-3.0]])\n",
    "\n",
    "x = np.linalg.solve(A.T @ A, A.T @ b)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d3a928",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Problems with the normal equations\n",
    "\n",
    "Consider the matrix $A = \\begin{pmatrix} 1 & 1 \\\\ \\varepsilon & 0 \\\\ 0 & \\varepsilon \\end{pmatrix}$, which gives\n",
    "\n",
    "$$\n",
    "A^T A = \\begin{pmatrix}\n",
    "1 + \\varepsilon^2 & 1 \\\\\n",
    "1 & 1 + \\varepsilon^2.\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "If $\\varepsilon \\approx \\sqrt{eps}$ then the effects of rounding error can make $A^T A$ appear to be singular.\n",
    "\n",
    "See also: Nick Higham, [Seven sins of numerical linear algebra](https://nhigham.com/2022/10/11/seven-sins-of-numerical-linear-algebra/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2427f6",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Sensitivity and conditioning\n",
    "\n",
    "-   The condition number of a square matrix $A$ describes how close that matrix is to being singular.\n",
    "\n",
    "-   If the condition number is larger then $A$ is \"close\" to being singular.\n",
    "\n",
    "-   When the condition number is very large it is likely that the effects of rounding errors will be most serious: we refer to such a system as being ill-conditioned.\n",
    "\n",
    "-   The normal equations are typically quite ill-conditioned and so it is essential to use high precision arithmetic to solve them and specialised algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e22474b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "-   Overdetermined systems are common in data modelling and they typically have no solution.\n",
    "\n",
    "-   Even so, it is possible to find a *closest* solution to the problem.\n",
    "\n",
    "-   It is common to measure this closeness in the Euclidean norm and this leads naturally to the least squares approximation.\n",
    "\n",
    "-   A solution to this problem can be found by solving the normal equations but can must be taken to use arithmetic with sufficient precision and specialised algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comp2421-book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
